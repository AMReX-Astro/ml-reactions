{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# include StarKiller library path\n",
    "import sys\n",
    "#sys.path.append( '/home/fanduomi/CCSE/Microphysics/python_library/' )\n",
    "sys.path.insert(0, '/home/fanduomi/CCSE/Microphysics/python_library') # ubuntu needs absolute path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from StarKiller.initialization import starkiller_initialize\n",
    "from StarKiller.interfaces import BurnType, EosType\n",
    "from StarKiller.integration import Integrator\n",
    "from StarKiller.network import Network\n",
    "from StarKiller.eos import Eos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starkiller_initialize(\"probin_aprox13\")\n",
    "network = Network()\n",
    "integrator = Integrator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set use_cuda=True to use an available GPU\n",
    "use_cuda=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input sampling domain & scaling\n",
    "dens = 1.0e8\n",
    "temp = 4.0e8\n",
    "xhe = 1.0\n",
    "\n",
    "end_time = 1.0\n",
    "\n",
    "time_scale = 1.0e-6\n",
    "density_scale = dens\n",
    "temperature_scale = temp * 10\n",
    "\n",
    "abs_tol = 1.0e-6\n",
    "rel_tol = 1.0e-6\n",
    "\n",
    "# do an eos call to set the internal energy scale\n",
    "eos = Eos()\n",
    "eos_state = EosType()\n",
    "\n",
    "eos_state.state.t = temp\n",
    "eos_state.state.rho = dens\n",
    "\n",
    "# pick a composition for normalization of Ye = 0.5 w/ abar = 12, zbar = 6\n",
    "eos_state.state.abar = 12.0\n",
    "eos_state.state.zbar = 6.0\n",
    "eos_state.state.y_e = eos_state.state.zbar / eos_state.state.abar\n",
    "eos_state.state.mu_e = 1.0 / eos_state.state.y_e\n",
    "\n",
    "# use_raw_inputs uses only abar, zbar, y_e, mu_e for the EOS call\n",
    "# instead of setting those from the mass fractions\n",
    "eos.evaluate(eos_state.eos_input_rt, eos_state, use_raw_inputs=True)\n",
    "\n",
    "energy_scale = eos_state.state.e\n",
    "\n",
    "print(\"density_scale = \", density_scale)\n",
    "print(\"temperature_scale = \", temperature_scale)\n",
    "print(\"energy_scale = \", energy_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size of training set\n",
    "NumSamples = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the solution given t\n",
    "def sol(t):\n",
    "    y = torch.zeros(NumSamples, network.nspec+2)\n",
    "    \n",
    "    for i, time in enumerate(t):\n",
    "        # get the time\n",
    "        time = time.item()\n",
    "        \n",
    "        # construct a burn type\n",
    "        state_in = BurnType()\n",
    "\n",
    "        # set density & temperature\n",
    "        state_in.state.rho = dens\n",
    "        state_in.state.t = temp\n",
    "\n",
    "        # mass fractions\n",
    "        state_in.state.xn = np.zeros(network.nspec)\n",
    "        state_in.state.xn[:] = (1.0-xhe)/(network.nspec-1)\n",
    "        state_in.state.xn[network.species_map[\"he4\"]] = xhe\n",
    "\n",
    "        # integrate to get the output state\n",
    "        state_out = integrator.integrate(state_in, time * time_scale)\n",
    "        \n",
    "        # set the solution values\n",
    "        for n in range(network.nspec):\n",
    "            y[i][n] = state_out.state.xn[n]\n",
    "        y[i][network.net_itemp] = state_out.state.t / temperature_scale\n",
    "        y[i][network.net_ienuc] = state_out.state.e / energy_scale\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the solution rhs given y\n",
    "# scaled solution: ys = y / y_scale\n",
    "# scaled time: ts = t / t_scale\n",
    "# f = dys/dts = (dy/y_scale) / (dt/t_scale) = (dy/dt) * (t_scale / y_scale)\n",
    "def rhs(y):\n",
    "    dydt = torch.zeros(NumSamples, network.nspec+2)\n",
    "\n",
    "    for i, yi in enumerate(y):\n",
    "        # construct a burn type\n",
    "        state = BurnType()\n",
    "\n",
    "        # set density & temperature\n",
    "        state.state.rho = dens\n",
    "        state.state.t = max(yi[network.net_itemp] * temperature_scale, 0.0)\n",
    "\n",
    "        # mass fractions\n",
    "        for n in range(network.nspec):\n",
    "            state.state.xn[n] = max(yi[n], 0.0)\n",
    "\n",
    "        # evaluate the rhs\n",
    "        network.rhs(state)\n",
    "        \n",
    "        # get rhs\n",
    "        f = network.rhs_to_x(state.ydot)\n",
    "        for n in range(network.nspec):\n",
    "            dydt[i][n] = f[n] * time_scale\n",
    "\n",
    "        dydt[i][network.net_itemp] = f[network.net_itemp] * time_scale / temperature_scale\n",
    "        dydt[i][network.net_ienuc] = f[network.net_ienuc] * time_scale / energy_scale\n",
    "            \n",
    "    return dydt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take random pairs of states in-between time interval\n",
    "def getPair(t, y):\n",
    "    index1 = random.randint(0,len(t)-1)\n",
    "    index2 = random.randint(0,len(t)-1)\n",
    "    \n",
    "    if t[index1] == t[index2]:\n",
    "        y0 = torch.cat((t[index1], y[0]),0)\n",
    "        return (y0, y[index1], t[index1])\n",
    "    \n",
    "    # return (dt, y0, yn)\n",
    "    if t[index1] < t[index2]:\n",
    "        y0 = torch.cat((t[index2]-t[index1], y[index1]),0)\n",
    "        return (y0, y[index2], t[index2])\n",
    "    else: \n",
    "        y0 = torch.cat((t[index1]-t[index2], y[index2]),0)\n",
    "        return (y0, y[index1], t[index1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = torch.unsqueeze(torch.linspace(0, 1.0, NumSamples, requires_grad=True), dim=1)\n",
    "t0_test = torch.unsqueeze(torch.rand(NumSamples, requires_grad=False), dim=1) * end_time\n",
    "\n",
    "# get the truth solution as a function of t\n",
    "y0 = sol(t0)\n",
    "\n",
    "# get the truth solution at times t_test\n",
    "y0_test = sol(t0_test)\n",
    "\n",
    "# get pairs of truth solutions (input state + dt, output truth state, time)\n",
    "x = torch.empty(NumSamples, y0.size()[1]+1)\n",
    "y = torch.empty(NumSamples, y0.size()[1])\n",
    "t = torch.empty(NumSamples, 1)\n",
    "\n",
    "x_test = torch.empty(NumSamples, y0_test.size()[1]+1)\n",
    "y_test = torch.empty(NumSamples, y0_test.size()[1])\n",
    "t_test = torch.empty(NumSamples, 1)\n",
    "\n",
    "for i in range(NumSamples):\n",
    "    x[i], y[i], t[i] = getPair(t0, y0)\n",
    "    x_test[i], y_test[i], t_test[i] = getPair(t0_test, y0_test)\n",
    "    \n",
    "# get the analytic right-hand-side as a function of y(x)\n",
    "# f(x) = dy(x)/dx\n",
    "dydx = rhs(y)\n",
    "\n",
    "if use_cuda:\n",
    "    x = x.cuda()\n",
    "    y = y.cuda()\n",
    "    x_test = x_test.cuda()\n",
    "    y_test = y_test.cuda()\n",
    "    dydx = dydx.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(t[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will want to propagate gradients through y, dydx, and x\n",
    "# so make them PyTorch Variables\n",
    "x = Variable(x, requires_grad=True)\n",
    "y = Variable(y, requires_grad=True)\n",
    "dydx = Variable(dydx, requires_grad=True)  # used in computing loss1 later\n",
    "\n",
    "# we will need to evaluate gradients w.r.t. x multiple\n",
    "# times so tell PyTorch to save the gradient variable in x.\n",
    "x.retain_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get numpy versions of x,y,f on the cpu for plotting\n",
    "tnp = t.cpu().data.numpy()\n",
    "ynp = y.cpu().data.numpy()\n",
    "fnp = dydx.cpu().data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the truth values\n",
    "fig, axis = plt.subplots(figsize=(5,5), dpi=150)\n",
    "axis_t = axis.twinx()\n",
    "\n",
    "for n in range(network.nspec):\n",
    "    axis.scatter(tnp, ynp[:,n],\n",
    "                 color='blue', alpha=0.5)\n",
    "    \n",
    "axis_t.scatter(tnp, ynp[:,network.net_itemp],\n",
    "               color='red', alpha=0.5)\n",
    "\n",
    "axis.set_ylabel(\"X\")\n",
    "axis.set_xlabel(\"t\")\n",
    "axis_t.set_ylabel(\"T\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the truth rhs\n",
    "fig, axis = plt.subplots(figsize=(5,5), dpi=150)\n",
    "axis_t = axis.twinx()\n",
    "\n",
    "for n in range(network.nspec):\n",
    "    axis.scatter(tnp, fnp[:,n],\n",
    "                 color='blue', alpha=0.5)\n",
    "    \n",
    "axis_t.scatter(tnp, fnp[:,network.net_itemp],\n",
    "               color='red', alpha=0.5)\n",
    "\n",
    "axis.set_ylabel(\"dX/dt\")\n",
    "axis.set_xlabel(\"t\")\n",
    "axis_t.set_ylabel(\"dT/dt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DenseNet has dense layers whose sizes change as follows:\n",
    "# (n_hidden, n_hidden-dn, n_hidden-2*dn, ..., n_hidden/2, n_hidden/2+dn, ..., n_hidden)\n",
    "# \n",
    "class DenseNet(nn.Module):\n",
    "    def __init__(self, n_independent, n_dependent,\n",
    "                 n_hidden, hidden_depth, activation):\n",
    "        super(DenseNet, self).__init__()\n",
    "        \n",
    "        self.activation = activation\n",
    "        self.input_layer = nn.Linear(n_independent, n_hidden)\n",
    "        \n",
    "        self.hidden_layers = nn.ModuleList()\n",
    "        dn = n_hidden//hidden_depth\n",
    "        half_depth = hidden_depth//2\n",
    "        for i in range(half_depth):\n",
    "            self.hidden_layers.append(nn.Linear(n_hidden-i*dn, n_hidden-(i+1)*dn))\n",
    "        \n",
    "        if hidden_depth%2 == 1:\n",
    "            self.hidden_layers.append(nn.Linear(n_hidden-half_depth*dn, n_hidden-half_depth*dn))\n",
    "            \n",
    "        for i in range(half_depth, 0, -1):\n",
    "            self.hidden_layers.append(nn.Linear(n_hidden-i*dn, n_hidden-(i-1)*dn))\n",
    "        \n",
    "        self.output_layer = nn.Linear(n_hidden, n_dependent)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.activation[0](self.input_layer(x))\n",
    "        \n",
    "        for i, h in enumerate(self.hidden_layers):\n",
    "            x = self.activation[i+1](h(x))\n",
    "        \n",
    "        x = self.output_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# activations, e.g. F.celu, torch.tanh\n",
    "activation = {}\n",
    "hidden_depth = 10\n",
    "\n",
    "for h in range(hidden_depth+1):\n",
    "    activation[h] = torch.tanh\n",
    "#     if h < hidden_depth/2:\n",
    "#         activation[h] = torch.tanh\n",
    "#     else:\n",
    "#         activation[h] = F.celu\n",
    "\n",
    "net = DenseNet(n_independent=network.nspec+3, n_dependent=network.nspec+2,\n",
    "                n_hidden=(network.nspec+3)*2, hidden_depth=hidden_depth,\n",
    "                activation=activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_cuda:\n",
    "    net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_sgd = torch.optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
    "optimizer_adam = torch.optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_images = []\n",
    "\n",
    "# get a multipanel figure showing the prediction (p) and error (e)\n",
    "%matplotlib agg\n",
    "\n",
    "fig, (axis_p, axis_f, axis_e) = plt.subplots(nrows=3, ncols=1, figsize=(8,8), dpi=150)\n",
    "axis_e1 = axis_e.twinx()\n",
    "axis_p_t = axis_p.twinx()\n",
    "axis_f_t = axis_f.twinx()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arrays for accumulating the epoch index and losses for plotting\n",
    "epochs = []\n",
    "losses = []\n",
    "losses0 = []\n",
    "losses1 = []\n",
    "tlosses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_loss(input, target):\n",
    "    return ((input - target)**2).sum() / input.data.nelement()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rms_weighted_error(input, target, solution, atol, rtol):\n",
    "    error_weight = atol + rtol * torch.abs(solution)\n",
    "    #error_weight = rtol * torch.abs(solution)\n",
    "    weighted_error = (input - target) / error_weight\n",
    "    rms_weighted_error = torch.sqrt((weighted_error**2).sum() / input.data.nelement())\n",
    "    return rms_weighted_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dydx.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this function is the training loop over epochs\n",
    "# where 1 epoch trains over the whole training dataset\n",
    "def train_error(NumEpochs, start_epoch=0):\n",
    "    total_time = 0.0\n",
    "    for i in range(NumEpochs):\n",
    "        i = i + start_epoch\n",
    "        \n",
    "        net_start_time = time.time()\n",
    "\n",
    "        # calculate prediction given the current net state\n",
    "        prediction = net(x)\n",
    "\n",
    "        # calculate error between prediction and analytic truth y\n",
    "        #loss0 = torch.sqrt(mse_loss(prediction, y))\n",
    "        loss0 = rms_weighted_error(prediction, y, y, abs_tol, rel_tol)\n",
    "\n",
    "        # first, zero out the existing gradients to avoid\n",
    "        # accumulating gradients on top of existing gradients\n",
    "        net.zero_grad()\n",
    "\n",
    "        # calculate gradients d(prediction)/d(x) for each component\n",
    "        def get_component_gradient(n):\n",
    "            if x.grad is not None:\n",
    "                x.grad.data.zero_()\n",
    "\n",
    "            # now get the gradients dp_n/dt\n",
    "            prediction[:,n].backward(torch.ones_like(prediction[:,n]), retain_graph=True)\n",
    "            # clone the x gradient to save a copy of it as dp_n/dt\n",
    "            # note that dt is in the first column of x -> x[0]\n",
    "            dpndt = x.grad[:,0].clone()\n",
    "            # clear the x gradient for the loss gradient below\n",
    "            x.grad.data.zero_()\n",
    "            \n",
    "            # return dp_n/dt\n",
    "            return dpndt\n",
    "        \n",
    "        dpdt = torch.ones_like(prediction)\n",
    "\n",
    "        for j in range(network.nspec+2):\n",
    "            dpdt[:,j] = torch.flatten(get_component_gradient(j))\n",
    "\n",
    "        # define the error of the prediction derivative using the analytic derivative\n",
    "        loss1 = torch.sqrt(loss_func(dpdt, dydx))\n",
    "        #loss1 = rms_weighted_error(dpdt, dydx, dydx, abs_tol, rel_tol)\n",
    "\n",
    "        # total error combines the error of the prediction (loss0) with \n",
    "        # the error of the prediction derivative (loss1)\n",
    "        loss = loss0 + loss1\n",
    "\n",
    "        # use the Adam optimizer\n",
    "        optimizer = optimizer_adam\n",
    "\n",
    "        # clear gradients for the next training iteration\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # compute backpropagation gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # apply gradients to update the weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        net_end_time = time.time()\n",
    "        net_time = net_end_time - net_start_time\n",
    "        total_time += net_time\n",
    "        average_net_time = total_time / (i - start_epoch + 1.0)\n",
    "\n",
    "        # generate plots\n",
    "        if i % 100 == 0:\n",
    "            # only calculate the following if we're doing I/O\n",
    "            # get error with testing samples\n",
    "            prediction_test = net(x_test)\n",
    "            #test_loss = torch.sqrt(loss_func(prediction_test, y_test)).cpu().data.numpy()\n",
    "            test_loss = rms_weighted_error(prediction_test, y_test, y_test, abs_tol, rel_tol)\n",
    "            test_loss = test_loss.cpu().data.numpy()\n",
    "        \n",
    "            # evaluate the analytic right-hand-side function at the prediction value\n",
    "            prhs = rhs(prediction)\n",
    "            \n",
    "            # Prediction plots to show learning progress\n",
    "            \n",
    "            # clear previously drawn curves\n",
    "            axis_p.clear()\n",
    "            axis_p_t.clear()\n",
    "\n",
    "            axis_p.set_ylabel('Solution', fontsize=22)\n",
    "\n",
    "            pnp = prediction.cpu().data.numpy()\n",
    "            \n",
    "            for n in range(network.nspec):\n",
    "                axis_p.scatter(tnp, pnp[:,n],\n",
    "                            color='green', s=20, alpha=0.5)\n",
    "\n",
    "                axis_p.scatter(tnp, ynp[:,n],\n",
    "                               color='blue', alpha=0.5, s=20)\n",
    "                \n",
    "            axis_p_t.scatter(tnp, pnp[:,network.net_itemp],\n",
    "                          color='green', s=20, alpha=0.5,\n",
    "                          label='p(t)')\n",
    "\n",
    "            axis_p_t.scatter(tnp, ynp[:,network.net_itemp],\n",
    "                             color='red', alpha=0.5, s=20,\n",
    "                             label='x(t)')\n",
    "\n",
    "            # Plot analytic rhs vs prediction rhs\n",
    "            pfnp = prhs.cpu().data.numpy()\n",
    "            dpdtnp = dpdt.cpu().data.numpy()\n",
    "            \n",
    "            # clear previously drawn curves\n",
    "            axis_f.clear()\n",
    "            axis_f_t.clear()\n",
    "\n",
    "            axis_f.set_ylabel('Gradient', fontsize=22)\n",
    "            \n",
    "            for n in range(network.nspec):\n",
    "                axis_f.scatter(tnp, pfnp[:,n],\n",
    "                            color='green', s=20, alpha=0.5)\n",
    "\n",
    "                axis_f.scatter(tnp, dpdtnp[:,n],\n",
    "                            color='magenta', s=20, alpha=0.5)\n",
    "\n",
    "                axis_f.scatter(tnp, fnp[:,n],\n",
    "                               color='blue', alpha=0.5, s=20)\n",
    "                \n",
    "            axis_f_t.scatter(tnp, pfnp[:,network.net_itemp],\n",
    "                          color='green', s=20, alpha=0.5,\n",
    "                          label='f(p(t))')\n",
    "\n",
    "            axis_f_t.scatter(tnp, dpdtnp[:,network.net_itemp],\n",
    "                          color='black', s=20, alpha=0.5,\n",
    "                          label='dp(t)/dt')\n",
    "\n",
    "            axis_f_t.scatter(tnp, fnp[:,network.net_itemp],\n",
    "                             color='red', alpha=0.5, s=20,\n",
    "                             label='f(x(t))')\n",
    "            \n",
    "            axis_f.tick_params(axis='both', which='major', labelsize=16)\n",
    "            axis_f_t.tick_params(axis='both', which='major', labelsize=16)\n",
    "            \n",
    "            axis_f_t.legend(loc='upper right', borderpad=1, framealpha=0.5)\n",
    "            \n",
    "            # get min/max in x/y to set label positions relative to the axes\n",
    "            xmin = 0\n",
    "            xmax = 1\n",
    "            ymin = 0\n",
    "            ymax = 1\n",
    "\n",
    "            height = np.abs(ymax - ymin)\n",
    "            width = np.abs(xmax - xmin)\n",
    "\n",
    "            axis_p.set_xlim(xmin, xmax)\n",
    "            axis_p.set_ylim(ymin, ymax)\n",
    "\n",
    "            axis_p.text(xmin, ymax + height*0.3,\n",
    "                      'Step = %d' % i, fontdict={'size': 24, 'color': 'blue'})\n",
    "            axis_p.text(xmin + width*0.5, ymax + height*0.3,\n",
    "                      'Train Loss = %.2e' % loss.cpu().data.numpy(),\n",
    "                      fontdict={'size': 24, 'color': 'blue'})\n",
    "            axis_p.text(xmin + width*0.5, ymax + height*0.1,\n",
    "                      'Test Loss = %.2e' % test_loss,\n",
    "                      fontdict={'size': 24, 'color': 'orange'})\n",
    "\n",
    "            axis_p.tick_params(axis='both', which='major', labelsize=16)\n",
    "            axis_p_t.tick_params(axis='both', which='major', labelsize=16)\n",
    "\n",
    "            # plot errors evolving with the number of epochs trained\n",
    "            epochs.append(i)\n",
    "            losses.append(loss.cpu().data.numpy())\n",
    "            losses0.append(loss0.cpu().data.numpy())\n",
    "            losses1.append(loss1.cpu().data.numpy())\n",
    "            tlosses.append(test_loss)\n",
    "\n",
    "            # clear previously drawn curves\n",
    "            axis_e.clear()\n",
    "            axis_e1.clear()\n",
    "\n",
    "            axis_e.set_xlabel('Epoch', fontsize=22)\n",
    "            axis_e.set_ylabel('E(p,x)', fontsize=22)\n",
    "\n",
    "            axis_e.scatter([epochs[-1]], [losses0[-1]],\n",
    "                           color=\"red\", alpha=0.5)\n",
    "            axis_e.plot(epochs, losses0,\n",
    "                        'b-', lw=3, alpha=0.5,\n",
    "                        label='E(p,x) [train]')\n",
    "\n",
    "            axis_e.scatter([epochs[-1]], [test_loss],\n",
    "                           color=\"red\", alpha=0.5)\n",
    "            axis_e.plot(epochs, tlosses,\n",
    "                        'orange', lw=3, ls=\"--\", alpha=0.5,\n",
    "                        label='E(p,x) [test]')\n",
    "\n",
    "            axis_e1.set_ylabel('E(dp/dt, f(x))', fontsize=22)\n",
    "            \n",
    "            axis_e1.scatter([epochs[-1]], [losses1[-1]],\n",
    "                           color=\"red\", alpha=0.5)\n",
    "            axis_e1.plot(epochs, losses1,\n",
    "                         'g-', lw=3, alpha=0.5,\n",
    "                         label='E(dp/dt, f(x)) [train]')\n",
    "            \n",
    "            axis_e.get_yaxis().set_major_formatter(\n",
    "                matplotlib.ticker.FuncFormatter(lambda x, p: \"{:0.1f}\".format(x)))\n",
    "            \n",
    "            axis_e1.get_yaxis().set_major_formatter(\n",
    "                matplotlib.ticker.FuncFormatter(lambda x, p: \"{:0.1f}\".format(x)))\n",
    "\n",
    "            axis_e.tick_params(axis='both', which='major', labelsize=16)\n",
    "            axis_e1.tick_params(axis='both', which='major', labelsize=16)\n",
    "            \n",
    "            axis_e.legend(loc='upper right', borderpad=1, framealpha=0.5)\n",
    "            axis_e1.legend(loc='upper center', borderpad=1, framealpha=0.5)\n",
    "            \n",
    "            # Draw on canvas and save image in sequence\n",
    "            fig.canvas.draw()\n",
    "            plt.tight_layout()\n",
    "            image = np.frombuffer(fig.canvas.tostring_rgb(), dtype='uint8')\n",
    "            image = image.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "\n",
    "            training_images.append(image)\n",
    "\n",
    "            # Print epoch/error notifications\n",
    "            if i % 100 == 0:\n",
    "                print(\"epoch \", i, \" with error: \", losses[-1],\n",
    "                      \"average time/epoch:\", average_net_time)\n",
    "           \n",
    "        # Stop early if our errors are plateauing\n",
    "        if i > 1000 and False:\n",
    "            # do a quadratic polynomial fit and see if we will\n",
    "            # need more than NumEpochs for the error e to vanish:\n",
    "            # e / (d(e)/d(epoch)) > NumEpochs ?\n",
    "            # if so, then break out of the training loop ...\n",
    "            xfit = epochs[-4:]\n",
    "            efit = losses[-4:]\n",
    "            coef = np.polyfit(xfit, efit, 2)\n",
    "            \n",
    "            if coef[2]/coef[1] > NumEpochs:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_error(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "imageio.mimsave('./starkiller2.gif', training_images, fps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"final test sample error: \", tlosses[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_test_np = net(x_test).cpu().data.numpy()\n",
    "y_test_np = y_test.cpu().data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_prediction_truth(label, p, t):\n",
    "    plt.clf()\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter(t, p)\n",
    "    ax.plot(t,t,'r')\n",
    "    ax.set_xlabel(\"truth {}\".format(label))\n",
    "    ax.set_ylabel(\"prediction {}\".format(label))\n",
    "    plt.savefig(\"prediction2_map_{}.png\".format(label), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(network.nspec+2):\n",
    "    plot_prediction_truth(n, prediction_test_np[:,n], y_test_np[:,n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
